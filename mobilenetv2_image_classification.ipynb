{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenetv2_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGqtxBiJLJdDeEwJLWMAg7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dritx16/transfer-learning/blob/main/mobilenetv2_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title Default title text\n",
        "# from zipfile import ZipFile\n",
        "# file_name = \"/archive.zip\"\n",
        "\n",
        "# with ZipFile(file_name, 'r') as zip:\n",
        "#   zip.extractall()\n",
        "#   print('Done')"
      ],
      "metadata": {
        "id": "DOvGjLlGV4Ia",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5549f8e2-d849-4cff-f62f-003a6653d9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg5HmT4Ot2PC"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# print(\"TF version:\", tf.__version__)\n",
        "# print(\"Hub version:\", hub.__version__)\n",
        "# print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Images**\n",
        "\n",
        "Dataset link : https://www.kaggle.com/niteshfre/chessman-image-dataset\n"
      ],
      "metadata": {
        "id": "E_IINHdkZN_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "path = \"/content/Chessman-image-dataset/Chess\"    # For other datasets, must be updated.\n",
        "data_dir = pathlib.Path(path)\n",
        "# data_dir"
      ],
      "metadata": {
        "id": "N82ACTgrWw1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class dictionaries\n",
        "chess_images_dict = {\n",
        "    'bishop' : list(data_dir.glob('Bishop/*')),\n",
        "    'king' : list(data_dir.glob('King/*')),\n",
        "    'knight' : list(data_dir.glob('Knight/*')),\n",
        "    'pawn' : list(data_dir.glob('Pawn/*')),\n",
        "    'queen' : list(data_dir.glob('Queen/*')),\n",
        "    'rook' : list(data_dir.glob('Rook/*')),\n",
        "}"
      ],
      "metadata": {
        "id": "B3Yw6I7Nq0W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess_labels_dict = {\n",
        "    'bishop' : 0,\n",
        "    'king' : 1,\n",
        "    'knight' : 2,\n",
        "    'pawn' : 3,\n",
        "    'queen' : 4,\n",
        "    'rook' : 5,\n",
        "}"
      ],
      "metadata": {
        "id": "r9xpBRt2q0Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Getting Images into train and test arrays**"
      ],
      "metadata": {
        "id": "45V7FREsZjlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = [], []\n",
        "IMAGE_SHAPE = (224, 224)    # Required image size for MobileNetV2.\n",
        "dataset_size = 0\n",
        "for item_name, items in chess_images_dict.items() :\n",
        "  for image in items :\n",
        "    img = cv2.imread(str(image))\n",
        "    dataset_size += 1\n",
        "    try :   # In case of errorness file types for cv2.\n",
        "      resized_img = cv2.resize(img, IMAGE_SHAPE)    # Resizing images to appropriate size for MobileNetV2.\n",
        "    except :\n",
        "      continue\n",
        "    x.append(resized_img)\n",
        "    y.append(chess_labels_dict[item_name])\n",
        "# dataset_size"
      ],
      "metadata": {
        "id": "ZeSHniCRq0Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "2tvORNr5uB79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing dataset into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75 , random_state=0)"
      ],
      "metadata": {
        "id": "WEjVrLOMuB5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "x_train_scaled = x_train / 255\n",
        "x_test_scaled = x_test / 255"
      ],
      "metadata": {
        "id": "tOzmWNG0yrzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Proccess\n",
        "\n",
        "For this project, MobileNetV2 is used."
      ],
      "metadata": {
        "id": "Sfv7rhNSbFXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing MobileNetV2 model from tensorflow hub.\n",
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "pretrained_model_without_top_layer = hub.KerasLayer(\n",
        "    feature_extractor_model, input_shape=(224, 224, 3), \n",
        "    trainable=False)"
      ],
      "metadata": {
        "id": "MPu8yx5WV0pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = len(chess_images_dict)   # For other datasets, must be updated.\n",
        "model = tf.keras.Sequential([\n",
        "                             pretrained_model_without_top_layer,\n",
        "                             tf.keras.layers.Dense(num_of_classes)\n",
        "                             ])\n",
        "BATCH_SIZE = 16\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8nL0zeLzIA8",
        "outputId": "7f7f7d1f-df00-491b-b5fb-2d0d29e9a19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 7686      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,265,670\n",
            "Trainable params: 7,686\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(x_train_scaled, y_train, epochs=10, steps_per_epoch=len(x_train) // BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYrpH1zozXGI",
        "outputId": "2c2b32c5-9c5f-4e9a-c107-e2b93474e90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - 14s 57ms/step - loss: 1.7770 - accuracy: 0.2957\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 1.0664 - accuracy: 0.6370\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.7816 - accuracy: 0.7909\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.6196 - accuracy: 0.8534\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.5162 - accuracy: 0.8870\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.4431 - accuracy: 0.9279\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.3706 - accuracy: 0.9471\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.3301 - accuracy: 0.9567\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - 2s 58ms/step - loss: 0.2884 - accuracy: 0.9688\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - 1s 57ms/step - loss: 0.2513 - accuracy: 0.9808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5bbb28910>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkVaYq3W5aSj",
        "outputId": "d5004155-c17a-4481-efb8-2a928581df28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 212ms/step - loss: 0.7307 - accuracy: 0.7410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7307054400444031, 0.7410072088241577]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}